{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Concurrency and Parallelism (Part 1)\n",
    "\n",
    "**Items 52-58**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 52: Use subprocess to Manage Child Processes\n",
    "\n",
    "### Overview\n",
    "\n",
    "Python has battle-hardened libraries for running and managing child processes. This makes it a great language for:\n",
    "- Gluing together other tools (command-line utilities)\n",
    "- Graduating shell scripts to Python for readability and maintainability\n",
    "- Consuming all CPU cores of a machine\n",
    "- Driving and coordinating CPU-intensive workloads\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "**Best choice for managing child processes:** `subprocess` built-in module\n",
    "\n",
    "**Two main approaches:**\n",
    "1. `subprocess.run()` - Simple convenience function\n",
    "2. `subprocess.Popen` - Advanced usage for pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic subprocess Usage with run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Simple subprocess execution\n",
    "result = subprocess.run(\n",
    "    ['echo', 'Hello from the child!'],\n",
    "    capture_output=True,\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "result.check_returncode()  # No exception means clean exit\n",
    "print(result.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Running Multiple Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Running multiple commands and collecting results\n",
    "commands = [\n",
    "    ['echo', 'First command'],\n",
    "    ['echo', 'Second command'],\n",
    "    ['echo', 'Third command']\n",
    "]\n",
    "\n",
    "results = []\n",
    "for cmd in commands:\n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        capture_output=True,\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    results.append(result.stdout.strip())\n",
    "\n",
    "print(\"All command outputs:\")\n",
    "for i, output in enumerate(results, 1):\n",
    "    print(f\"{i}. {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Popen for Non-blocking Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Non-blocking subprocess with Popen\n",
    "proc = subprocess.Popen(['sleep', '1'])\n",
    "\n",
    "while proc.poll() is None:\n",
    "    print('Working...')\n",
    "    # Some time-consuming work here\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print('Exit status', proc.poll())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Subprocess Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start multiple processes in parallel\n",
    "start = time.time()\n",
    "sleep_procs = []\n",
    "\n",
    "for _ in range(10):\n",
    "    proc = subprocess.Popen(['sleep', '1'])\n",
    "    sleep_procs.append(proc)\n",
    "\n",
    "# Wait for all processes to complete\n",
    "for proc in sleep_procs:\n",
    "    proc.communicate()\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Finished in {delta:.3} seconds')\n",
    "print(f\"Expected: ~1 second (parallel execution)\")\n",
    "print(f\"Without parallelism: ~10 seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piping Data Between Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_encrypt(data):\n",
    "    \"\"\"Encrypt data using openssl (example)\"\"\"\n",
    "    env = os.environ.copy()\n",
    "    env['password'] = 'zf7ShyBhZOraQDdE/FiZpm/m/8f9X+M1'\n",
    "    \n",
    "    proc = subprocess.Popen(\n",
    "        ['openssl', 'enc', '-des3', '-pass', 'env:password'],\n",
    "        env=env,\n",
    "        stdin=subprocess.PIPE,\n",
    "        stdout=subprocess.PIPE\n",
    "    )\n",
    "    \n",
    "    proc.stdin.write(data)\n",
    "    proc.stdin.flush()  # Ensure the child gets input\n",
    "    return proc\n",
    "\n",
    "# Example: Encrypt multiple pieces of data in parallel\n",
    "procs = []\n",
    "for _ in range(3):\n",
    "    data = os.urandom(10)\n",
    "    proc = run_encrypt(data)\n",
    "    procs.append(proc)\n",
    "\n",
    "# Collect results\n",
    "for proc in procs:\n",
    "    out, _ = proc.communicate()\n",
    "    print(f\"Encrypted output (last 10 bytes): {out[-10:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Process Pipelines (UNIX-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_hash(input_stdin):\n",
    "    \"\"\"Generate a Whirlpool hash of the input stream\"\"\"\n",
    "    return subprocess.Popen(\n",
    "        ['openssl', 'dgst', '-whirlpool', '-binary'],\n",
    "        stdin=input_stdin,\n",
    "        stdout=subprocess.PIPE\n",
    "    )\n",
    "\n",
    "# Create a pipeline: encrypt -> hash\n",
    "encrypt_procs = []\n",
    "hash_procs = []\n",
    "\n",
    "for _ in range(3):\n",
    "    data = os.urandom(100)\n",
    "    \n",
    "    # Start encryption\n",
    "    encrypt_proc = run_encrypt(data)\n",
    "    encrypt_procs.append(encrypt_proc)\n",
    "    \n",
    "    # Chain with hashing\n",
    "    hash_proc = run_hash(encrypt_proc.stdout)\n",
    "    hash_procs.append(hash_proc)\n",
    "    \n",
    "    # Critical: Close stdout to allow SIGPIPE propagation\n",
    "    encrypt_proc.stdout.close()\n",
    "    encrypt_proc.stdout = None\n",
    "\n",
    "# Wait for all processes\n",
    "for proc in encrypt_procs:\n",
    "    proc.communicate()\n",
    "    assert proc.returncode == 0\n",
    "\n",
    "for proc in hash_procs:\n",
    "    out, _ = proc.communicate()\n",
    "    print(f\"Hash output (last 10 bytes): {out[-10:]}\")\n",
    "    assert proc.returncode == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Using timeout to prevent hanging processes\n",
    "proc = subprocess.Popen(['sleep', '10'])\n",
    "\n",
    "try:\n",
    "    proc.communicate(timeout=0.1)\n",
    "except subprocess.TimeoutExpired:\n",
    "    proc.terminate()\n",
    "    proc.wait()\n",
    "\n",
    "print('Exit status', proc.poll())\n",
    "print('Process was terminated due to timeout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Process Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "class ProcessManager:\n",
    "    \"\"\"Manages multiple child processes with timeout support\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.processes = []\n",
    "    \n",
    "    def start_process(self, command: List[str]) -> subprocess.Popen:\n",
    "        \"\"\"Start a new process\"\"\"\n",
    "        proc = subprocess.Popen(\n",
    "            command,\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE\n",
    "        )\n",
    "        self.processes.append(proc)\n",
    "        return proc\n",
    "    \n",
    "    def wait_all(self, timeout: float = None) -> List[Tuple[int, str, str]]:\n",
    "        \"\"\"Wait for all processes to complete\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for proc in self.processes:\n",
    "            try:\n",
    "                stdout, stderr = proc.communicate(timeout=timeout)\n",
    "                results.append((\n",
    "                    proc.returncode,\n",
    "                    stdout.decode('utf-8') if stdout else '',\n",
    "                    stderr.decode('utf-8') if stderr else ''\n",
    "                ))\n",
    "            except subprocess.TimeoutExpired:\n",
    "                proc.kill()\n",
    "                results.append((-1, '', 'Timeout'))\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "manager = ProcessManager()\n",
    "manager.start_process(['echo', 'Process 1'])\n",
    "manager.start_process(['echo', 'Process 2'])\n",
    "manager.start_process(['echo', 'Process 3'])\n",
    "\n",
    "results = manager.wait_all(timeout=5.0)\n",
    "for i, (returncode, stdout, stderr) in enumerate(results, 1):\n",
    "    print(f\"Process {i}: returncode={returncode}, output={stdout.strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ Use the `subprocess` module to run child processes and manage their input and output streams.\n",
    "\n",
    "✦ Child processes run in parallel with the Python interpreter, enabling you to maximize your usage of CPU cores.\n",
    "\n",
    "✦ Use the `run` convenience function for simple usage, and the `Popen` class for advanced usage like UNIX-style pipelines.\n",
    "\n",
    "✦ Use the `timeout` parameter of the `communicate` method to avoid deadlocks and hanging child processes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 53: Use Threads for Blocking I/O, Avoid for Parallelism\n",
    "\n",
    "### Understanding CPython and the GIL\n",
    "\n",
    "**CPython execution steps:**\n",
    "1. Parse and compile source text into bytecode\n",
    "2. Run bytecode using a stack-based interpreter\n",
    "\n",
    "**Global Interpreter Lock (GIL):**\n",
    "- Mutual-exclusion lock (mutex)\n",
    "- Prevents preemptive multithreading from corrupting interpreter state\n",
    "- Only one thread makes forward progress at a time\n",
    "- Ensures bytecode instruction correctness\n",
    "\n",
    "**Important:** The GIL prevents parallel CPU computation in Python threads!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: CPU-Bound Task (GIL Impact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def factorize(number):\n",
    "    \"\"\"Find all factors of a number\"\"\"\n",
    "    for i in range(1, number + 1):\n",
    "        if number % i == 0:\n",
    "            yield i\n",
    "\n",
    "# Serial execution\n",
    "numbers = [2139079, 1214759, 1516637, 1852285]\n",
    "start = time.time()\n",
    "\n",
    "for number in numbers:\n",
    "    list(factorize(number))\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Took {delta:.3f} seconds (serial)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting Multi-threaded Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "class FactorizeThread(Thread):\n",
    "    def __init__(self, number):\n",
    "        super().__init__()\n",
    "        self.number = number\n",
    "    \n",
    "    def run(self):\n",
    "        self.factors = list(factorize(self.number))\n",
    "\n",
    "# Multi-threaded execution\n",
    "start = time.time()\n",
    "threads = []\n",
    "\n",
    "for number in numbers:\n",
    "    thread = FactorizeThread(number)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Took {delta:.3f} seconds (multi-threaded)')\n",
    "print(f'Expected faster, but actually slower due to GIL overhead!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Demonstrating GIL Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from threading import Thread\n",
    "\n",
    "def cpu_intensive_task(iterations):\n",
    "    \"\"\"CPU-intensive calculation\"\"\"\n",
    "    result = 0\n",
    "    for i in range(iterations):\n",
    "        result += i ** 2\n",
    "    return result\n",
    "\n",
    "def benchmark_threads(num_threads, iterations):\n",
    "    \"\"\"Benchmark thread performance\"\"\"\n",
    "    threads = []\n",
    "    start = time.time()\n",
    "    \n",
    "    for _ in range(num_threads):\n",
    "        thread = Thread(\n",
    "            target=cpu_intensive_task,\n",
    "            args=(iterations,)\n",
    "        )\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    return time.time() - start\n",
    "\n",
    "# Compare single vs multi-threaded\n",
    "iterations = 1000000\n",
    "\n",
    "single_time = benchmark_threads(1, iterations)\n",
    "multi_time = benchmark_threads(4, iterations)\n",
    "\n",
    "print(f\"Single thread: {single_time:.3f} seconds\")\n",
    "print(f\"Four threads: {multi_time:.3f} seconds\")\n",
    "print(f\"Speedup: {single_time / multi_time:.2f}x\")\n",
    "print(f\"Expected: 4x speedup, Actual: ~1x due to GIL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Threads? Reason 1: Concurrent Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def task_a():\n",
    "    print(\"Task A: Starting\")\n",
    "    time.sleep(2)\n",
    "    print(\"Task A: Completed\")\n",
    "\n",
    "def task_b():\n",
    "    print(\"Task B: Starting\")\n",
    "    time.sleep(1)\n",
    "    print(\"Task B: Completed\")\n",
    "\n",
    "# Without threads (sequential)\n",
    "print(\"=== Sequential Execution ===\")\n",
    "start = time.time()\n",
    "task_a()\n",
    "task_b()\n",
    "print(f\"Total time: {time.time() - start:.3f} seconds\\n\")\n",
    "\n",
    "# With threads (concurrent)\n",
    "print(\"=== Concurrent Execution ===\")\n",
    "start = time.time()\n",
    "thread_a = Thread(target=task_a)\n",
    "thread_b = Thread(target=task_b)\n",
    "thread_a.start()\n",
    "thread_b.start()\n",
    "thread_a.join()\n",
    "thread_b.join()\n",
    "print(f\"Total time: {time.time() - start:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Threads? Reason 2: Blocking I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import select\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def slow_systemcall():\n",
    "    \"\"\"Simulate a slow system call (e.g., network I/O)\"\"\"\n",
    "    select.select([socket.socket()], [], [], 0.1)\n",
    "\n",
    "# Serial execution of I/O operations\n",
    "start = time.time()\n",
    "for _ in range(5):\n",
    "    slow_systemcall()\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Serial I/O took {delta:.3f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel I/O with Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "# Parallel I/O operations\n",
    "start = time.time()\n",
    "threads = []\n",
    "\n",
    "for _ in range(5):\n",
    "    thread = Thread(target=slow_systemcall)\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Simulate computation while I/O happens\n",
    "def compute_helicopter_location(index):\n",
    "    \"\"\"Simulate some computation\"\"\"\n",
    "    pass\n",
    "\n",
    "for i in range(5):\n",
    "    compute_helicopter_location(i)\n",
    "\n",
    "# Wait for all I/O to complete\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "end = time.time()\n",
    "delta = end - start\n",
    "print(f'Parallel I/O took {delta:.3f} seconds')\n",
    "print(f'Speedup: ~5x faster than serial execution!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Concurrent File Download Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "class FileDownloader(Thread):\n",
    "    \"\"\"Simulate downloading a file\"\"\"\n",
    "    \n",
    "    def __init__(self, file_id: int, size_mb: float):\n",
    "        super().__init__()\n",
    "        self.file_id = file_id\n",
    "        self.size_mb = size_mb\n",
    "        self.download_time = None\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"Simulate download (I/O operation)\"\"\"\n",
    "        start = time.time()\n",
    "        # Simulate network I/O\n",
    "        time.sleep(self.size_mb * 0.1)  # 0.1 sec per MB\n",
    "        self.download_time = time.time() - start\n",
    "        print(f\"File {self.file_id}: Downloaded {self.size_mb}MB in {self.download_time:.2f}s\")\n",
    "\n",
    "# Download files concurrently\n",
    "files_to_download = [10, 15, 8, 12, 20]  # File sizes in MB\n",
    "\n",
    "print(\"=== Sequential Downloads ===\")\n",
    "start = time.time()\n",
    "for i, size in enumerate(files_to_download):\n",
    "    downloader = FileDownloader(i, size)\n",
    "    downloader.run()  # Run sequentially\n",
    "sequential_time = time.time() - start\n",
    "print(f\"Total time: {sequential_time:.2f}s\\n\")\n",
    "\n",
    "print(\"=== Concurrent Downloads ===\")\n",
    "start = time.time()\n",
    "threads: List[FileDownloader] = []\n",
    "for i, size in enumerate(files_to_download):\n",
    "    downloader = FileDownloader(i, size)\n",
    "    downloader.start()\n",
    "    threads.append(downloader)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "concurrent_time = time.time() - start\n",
    "print(f\"\\nTotal time: {concurrent_time:.2f}s\")\n",
    "print(f\"Speedup: {sequential_time / concurrent_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ Python threads can't run in parallel on multiple CPU cores because of the global interpreter lock (GIL).\n",
    "\n",
    "✦ Python threads are still useful despite the GIL because they provide an easy way to do multiple things seemingly at the same time.\n",
    "\n",
    "✦ Use Python threads to make multiple system calls in parallel. This allows you to do blocking I/O at the same time as computation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 54: Use Lock to Prevent Data Races in Threads\n",
    "\n",
    "### The GIL Misconception\n",
    "\n",
    "**Important:** The GIL does NOT protect you from data races!\n",
    "\n",
    "**Why?** Thread operations can be interrupted between any two bytecode instructions.\n",
    "\n",
    "**Result:** Data structure invariants can be violated, leaving your program in a corrupted state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Data Race Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "    \n",
    "    def increment(self, offset):\n",
    "        self.count += offset\n",
    "\n",
    "# Simulate sensor readings\n",
    "def worker(sensor_index, how_many, counter):\n",
    "    for _ in range(how_many):\n",
    "        # Read from the sensor\n",
    "        counter.increment(1)\n",
    "\n",
    "# Run with multiple threads\n",
    "from threading import Thread\n",
    "\n",
    "how_many = 10**5\n",
    "counter = Counter()\n",
    "threads = []\n",
    "\n",
    "for i in range(5):\n",
    "    thread = Thread(target=worker, args=(i, how_many, counter))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "expected = how_many * 5\n",
    "found = counter.count\n",
    "print(f'Counter should be {expected}, got {found}')\n",
    "print(f'Data race occurred! Lost {expected - found} increments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data Race\n",
    "\n",
    "The operation `counter.count += 1` is actually three operations:\n",
    "\n",
    "```python\n",
    "value = getattr(counter, 'count')\n",
    "result = value + 1\n",
    "setattr(counter, 'count', result)\n",
    "```\n",
    "\n",
    "**Race condition example:**\n",
    "```\n",
    "Thread A: value_a = getattr(counter, 'count')  # Gets 0\n",
    "[Context switch to Thread B]\n",
    "Thread B: value_b = getattr(counter, 'count')  # Gets 0\n",
    "Thread B: result_b = value_b + 1               # 1\n",
    "Thread B: setattr(counter, 'count', result_b)  # Sets to 1\n",
    "[Context switch to Thread A]\n",
    "Thread A: result_a = value_a + 1               # 1\n",
    "Thread A: setattr(counter, 'count', result_a)  # Sets to 1 (overwrites B's work!)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Using Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread\n",
    "\n",
    "class LockingCounter:\n",
    "    def __init__(self):\n",
    "        self.lock = Lock()\n",
    "        self.count = 0\n",
    "    \n",
    "    def increment(self, offset):\n",
    "        with self.lock:\n",
    "            self.count += offset\n",
    "\n",
    "# Run with Lock protection\n",
    "counter = LockingCounter()\n",
    "threads = []\n",
    "\n",
    "for i in range(5):\n",
    "    thread = Thread(target=worker, args=(i, how_many, counter))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "expected = how_many * 5\n",
    "found = counter.count\n",
    "print(f'Counter should be {expected}, got {found}')\n",
    "print('Lock solved the problem!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Bank Account Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread\n",
    "import time\n",
    "import random\n",
    "\n",
    "class BankAccount:\n",
    "    \"\"\"Thread-safe bank account\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_balance):\n",
    "        self.lock = Lock()\n",
    "        self.balance = initial_balance\n",
    "    \n",
    "    def deposit(self, amount):\n",
    "        with self.lock:\n",
    "            new_balance = self.balance + amount\n",
    "            time.sleep(0.0001)  # Simulate processing time\n",
    "            self.balance = new_balance\n",
    "    \n",
    "    def withdraw(self, amount):\n",
    "        with self.lock:\n",
    "            if self.balance >= amount:\n",
    "                new_balance = self.balance - amount\n",
    "                time.sleep(0.0001)  # Simulate processing time\n",
    "                self.balance = new_balance\n",
    "                return True\n",
    "            return False\n",
    "    \n",
    "    def get_balance(self):\n",
    "        with self.lock:\n",
    "            return self.balance\n",
    "\n",
    "def random_transactions(account, num_transactions):\n",
    "    \"\"\"Perform random deposits and withdrawals\"\"\"\n",
    "    for _ in range(num_transactions):\n",
    "        if random.choice([True, False]):\n",
    "            account.deposit(random.randint(1, 100))\n",
    "        else:\n",
    "            account.withdraw(random.randint(1, 100))\n",
    "\n",
    "# Test with multiple threads\n",
    "account = BankAccount(1000)\n",
    "print(f\"Initial balance: ${account.get_balance()}\")\n",
    "\n",
    "threads = []\n",
    "for i in range(10):\n",
    "    thread = Thread(target=random_transactions, args=(account, 100))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"Final balance: ${account.get_balance()}\")\n",
    "print(\"All transactions completed safely!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Shared Resource Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "class ResourcePool:\n",
    "    \"\"\"Thread-safe resource pool\"\"\"\n",
    "    \n",
    "    def __init__(self, resources: List[str]):\n",
    "        self.lock = Lock()\n",
    "        self.available = list(resources)\n",
    "        self.in_use = []\n",
    "    \n",
    "    def acquire(self) -> str:\n",
    "        \"\"\"Acquire a resource from the pool\"\"\"\n",
    "        with self.lock:\n",
    "            if not self.available:\n",
    "                return None\n",
    "            resource = self.available.pop(0)\n",
    "            self.in_use.append(resource)\n",
    "            return resource\n",
    "    \n",
    "    def release(self, resource: str):\n",
    "        \"\"\"Release a resource back to the pool\"\"\"\n",
    "        with self.lock:\n",
    "            if resource in self.in_use:\n",
    "                self.in_use.remove(resource)\n",
    "                self.available.append(resource)\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get current pool statistics\"\"\"\n",
    "        with self.lock:\n",
    "            return {\n",
    "                'available': len(self.available),\n",
    "                'in_use': len(self.in_use),\n",
    "                'total': len(self.available) + len(self.in_use)\n",
    "            }\n",
    "\n",
    "def use_resource(pool, worker_id, duration):\n",
    "    \"\"\"Worker that uses a resource\"\"\"\n",
    "    resource = pool.acquire()\n",
    "    if resource:\n",
    "        print(f\"Worker {worker_id}: Using {resource}\")\n",
    "        time.sleep(duration)\n",
    "        pool.release(resource)\n",
    "        print(f\"Worker {worker_id}: Released {resource}\")\n",
    "    else:\n",
    "        print(f\"Worker {worker_id}: No resources available\")\n",
    "\n",
    "# Test resource pool\n",
    "pool = ResourcePool(['Resource-A', 'Resource-B', 'Resource-C'])\n",
    "\n",
    "threads = []\n",
    "for i in range(5):\n",
    "    thread = Thread(target=use_resource, args=(pool, i, 0.5))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(f\"\\nFinal stats: {pool.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ Even though Python has a global interpreter lock, you're still responsible for protecting against data races between the threads in your programs.\n",
    "\n",
    "✦ Your programs will corrupt their data structures if you allow multiple threads to modify the same objects without mutual-exclusion locks (mutexes).\n",
    "\n",
    "✦ Use the `Lock` class from the `threading` built-in module to enforce your program's invariants between multiple threads.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 55: Use Queue to Coordinate Work Between Threads\n",
    "\n",
    "### Pipeline Concept\n",
    "\n",
    "**Pipeline:** An assembly line approach with multiple phases in serial\n",
    "- Each phase has a specific function\n",
    "- Work moves forward through phases\n",
    "- Functions can operate concurrently\n",
    "- Especially good for blocking I/O or subprocesses\n",
    "\n",
    "**Example scenario:** Image processing pipeline\n",
    "1. Download images\n",
    "2. Resize images\n",
    "3. Upload images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Implementation: Custom Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from threading import Lock\n",
    "\n",
    "class MyQueue:\n",
    "    \"\"\"Simple thread-safe queue\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.items = deque()\n",
    "        self.lock = Lock()\n",
    "    \n",
    "    def put(self, item):\n",
    "        \"\"\"Producer adds items to the queue\"\"\"\n",
    "        with self.lock:\n",
    "            self.items.append(item)\n",
    "    \n",
    "    def get(self):\n",
    "        \"\"\"Consumer removes items from the queue\"\"\"\n",
    "        with self.lock:\n",
    "            return self.items.popleft()\n",
    "\n",
    "# Example pipeline functions\n",
    "def download(item):\n",
    "    \"\"\"Download an image\"\"\"\n",
    "    return item\n",
    "\n",
    "def resize(item):\n",
    "    \"\"\"Resize an image\"\"\"\n",
    "    return item\n",
    "\n",
    "def upload(item):\n",
    "    \"\"\"Upload an image\"\"\"\n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worker Thread with Busy Waiting (Problematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "class Worker(Thread):\n",
    "    \"\"\"Worker that polls for work (busy waiting)\"\"\"\n",
    "    \n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "        self.polled_count = 0\n",
    "        self.work_done = 0\n",
    "    \n",
    "    def run(self):\n",
    "        while True:\n",
    "            self.polled_count += 1\n",
    "            try:\n",
    "                item = self.in_queue.get()\n",
    "            except IndexError:\n",
    "                time.sleep(0.01)  # No work to do\n",
    "            else:\n",
    "                result = self.func(item)\n",
    "                self.out_queue.put(result)\n",
    "                self.work_done += 1\n",
    "\n",
    "print(\"This implementation has problems:\")\n",
    "print(\"1. Busy waiting wastes CPU\")\n",
    "print(\"2. Hard to determine when all work is done\")\n",
    "print(\"3. No way to signal workers to exit\")\n",
    "print(\"4. Can cause memory explosion if producer is faster than consumer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Solution: Using Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "# Queue eliminates busy waiting\n",
    "my_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    my_queue.get()  # Blocks until item available\n",
    "    print('Consumer done')\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "print('Producer putting')\n",
    "my_queue.put(object())\n",
    "print('Producer done')\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue with Buffer Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "my_queue = Queue(1)  # Buffer size of 1\n",
    "\n",
    "def consumer():\n",
    "    time.sleep(0.1)  # Wait\n",
    "    my_queue.get()   # Runs second\n",
    "    print('Consumer got 1')\n",
    "    my_queue.get()   # Runs fourth\n",
    "    print('Consumer got 2')\n",
    "    print('Consumer done')\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "my_queue.put(object())  # Runs first\n",
    "print('Producer put 1')\n",
    "my_queue.put(object())  # Runs third (blocks until consumer gets first)\n",
    "print('Producer put 2')\n",
    "print('Producer done')\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using task_done() and join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "in_queue = Queue()\n",
    "\n",
    "def consumer():\n",
    "    print('Consumer waiting')\n",
    "    work = in_queue.get()  # Runs second\n",
    "    print('Consumer working')\n",
    "    # Doing work...\n",
    "    print('Consumer done')\n",
    "    in_queue.task_done()   # Runs third\n",
    "\n",
    "thread = Thread(target=consumer)\n",
    "thread.start()\n",
    "\n",
    "print('Producer putting')\n",
    "in_queue.put(object())  # Runs first\n",
    "print('Producer waiting')\n",
    "in_queue.join()         # Runs fourth (blocks until task_done called)\n",
    "print('Producer done')\n",
    "thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Pipeline with ClosableQueue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "class ClosableQueue(Queue):\n",
    "    \"\"\"Queue that can signal end of data\"\"\"\n",
    "    SENTINEL = object()\n",
    "    \n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return  # Cause the thread to exit\n",
    "                yield item\n",
    "            finally:\n",
    "                self.task_done()\n",
    "\n",
    "class StoppableWorker(Thread):\n",
    "    \"\"\"Worker that can be stopped cleanly\"\"\"\n",
    "    \n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "    \n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)\n",
    "\n",
    "print(\"ClosableQueue benefits:\")\n",
    "print(\"1. No busy waiting\")\n",
    "print(\"2. Bounded buffer prevents memory explosion\")\n",
    "print(\"3. Clean worker shutdown with sentinel value\")\n",
    "print(\"4. Progress tracking with task_done/join\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Image Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "class ClosableQueue(Queue):\n",
    "    SENTINEL = object()\n",
    "    \n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return\n",
    "                yield item\n",
    "            finally:\n",
    "                self.task_done()\n",
    "\n",
    "class StoppableWorker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "    \n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)\n",
    "\n",
    "# Pipeline functions with simulated I/O\n",
    "def download(item):\n",
    "    time.sleep(0.01)  # Simulate network I/O\n",
    "    return f\"Downloaded-{item}\"\n",
    "\n",
    "def resize(item):\n",
    "    time.sleep(0.01)  # Simulate CPU work\n",
    "    return f\"Resized-{item}\"\n",
    "\n",
    "def upload(item):\n",
    "    time.sleep(0.01)  # Simulate network I/O\n",
    "    return f\"Uploaded-{item}\"\n",
    "\n",
    "# Create queues\n",
    "download_queue = ClosableQueue()\n",
    "resize_queue = ClosableQueue()\n",
    "upload_queue = ClosableQueue()\n",
    "done_queue = ClosableQueue()\n",
    "\n",
    "# Create worker threads\n",
    "threads = [\n",
    "    StoppableWorker(download, download_queue, resize_queue),\n",
    "    StoppableWorker(resize, resize_queue, upload_queue),\n",
    "    StoppableWorker(upload, upload_queue, done_queue),\n",
    "]\n",
    "\n",
    "# Start all workers\n",
    "for thread in threads:\n",
    "    thread.start()\n",
    "\n",
    "# Add work to pipeline\n",
    "for i in range(10):\n",
    "    download_queue.put(f\"Image-{i}\")\n",
    "\n",
    "# Close pipeline\n",
    "download_queue.close()\n",
    "download_queue.join()\n",
    "resize_queue.close()\n",
    "resize_queue.join()\n",
    "upload_queue.close()\n",
    "upload_queue.join()\n",
    "\n",
    "# Collect results\n",
    "print(f\"{done_queue.qsize()} items finished\")\n",
    "print(\"\\nSample results:\")\n",
    "for i in range(min(3, done_queue.qsize())):\n",
    "    print(f\"  {done_queue.get()}\")\n",
    "\n",
    "# Clean up\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Workers Per Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_threads(count, *args):\n",
    "    \"\"\"Start multiple worker threads\"\"\"\n",
    "    threads = [StoppableWorker(*args) for _ in range(count)]\n",
    "    for thread in threads:\n",
    "        thread.start()\n",
    "    return threads\n",
    "\n",
    "def stop_threads(closable_queue, threads):\n",
    "    \"\"\"Stop all worker threads cleanly\"\"\"\n",
    "    for _ in threads:\n",
    "        closable_queue.close()\n",
    "    \n",
    "    closable_queue.join()\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "# Create queues\n",
    "download_queue = ClosableQueue()\n",
    "resize_queue = ClosableQueue()\n",
    "upload_queue = ClosableQueue()\n",
    "done_queue = ClosableQueue()\n",
    "\n",
    "# Start multiple workers per stage\n",
    "download_threads = start_threads(3, download, download_queue, resize_queue)\n",
    "resize_threads = start_threads(4, resize, resize_queue, upload_queue)\n",
    "upload_threads = start_threads(5, upload, upload_queue, done_queue)\n",
    "\n",
    "# Add work\n",
    "for i in range(100):\n",
    "    download_queue.put(f\"Image-{i}\")\n",
    "\n",
    "# Stop all stages\n",
    "stop_threads(download_queue, download_threads)\n",
    "stop_threads(resize_queue, resize_threads)\n",
    "stop_threads(upload_queue, upload_threads)\n",
    "\n",
    "print(f\"{done_queue.qsize()} items finished\")\n",
    "print(\"\\nParallel processing achieved with multiple workers per stage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ Pipelines are a great way to organize sequences of work—especially I/O-bound programs—that run concurrently using multiple Python threads.\n",
    "\n",
    "✦ Be aware of the many problems in building concurrent pipelines: busy waiting, how to tell workers to stop, and potential memory explosion.\n",
    "\n",
    "✦ The `Queue` class has all the facilities you need to build robust pipelines: blocking operations, buffer sizes, and joining.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 56: Know How to Recognize When Concurrency Is Necessary\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "As programs grow in scope and complexity:\n",
    "- Requirements expand\n",
    "- Single-threaded approach becomes limiting\n",
    "- Need for concurrent execution emerges\n",
    "\n",
    "**Most difficult change:** Moving from single-threaded to concurrent execution\n",
    "\n",
    "### Example: Conway's Game of Life\n",
    "\n",
    "**Rules:**\n",
    "- 2D grid of arbitrary size\n",
    "- Each cell: alive (`*`) or empty (`-`)\n",
    "- Each tick: cells count neighbors and decide state\n",
    "- State decisions:\n",
    "  - Die if < 2 neighbors (too few)\n",
    "  - Die if > 3 neighbors (too many)\n",
    "  - Regenerate if exactly 3 neighbors (empty cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Grid Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALIVE = '*'\n",
    "EMPTY = '-'\n",
    "\n",
    "class Grid:\n",
    "    \"\"\"2D grid for Game of Life\"\"\"\n",
    "    \n",
    "    def __init__(self, height, width):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.rows = []\n",
    "        for _ in range(self.height):\n",
    "            self.rows.append([EMPTY] * self.width)\n",
    "    \n",
    "    def get(self, y, x):\n",
    "        \"\"\"Get cell state (wraps around edges)\"\"\"\n",
    "        return self.rows[y % self.height][x % self.width]\n",
    "    \n",
    "    def set(self, y, x, state):\n",
    "        \"\"\"Set cell state\"\"\"\n",
    "        self.rows[y % self.height][x % self.width] = state\n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"String representation\"\"\"\n",
    "        result = []\n",
    "        for row in self.rows:\n",
    "            result.append(''.join(row))\n",
    "        return '\\n'.join(result)\n",
    "\n",
    "# Create grid and set up a glider pattern\n",
    "grid = Grid(5, 9)\n",
    "grid.set(0, 3, ALIVE)\n",
    "grid.set(1, 4, ALIVE)\n",
    "grid.set(2, 2, ALIVE)\n",
    "grid.set(2, 3, ALIVE)\n",
    "grid.set(2, 4, ALIVE)\n",
    "\n",
    "print(\"Initial grid state:\")\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Logic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_neighbors(y, x, get):\n",
    "    \"\"\"Count living neighbors around a cell\"\"\"\n",
    "    n_ = get(y - 1, x + 0)  # North\n",
    "    ne = get(y - 1, x + 1)  # Northeast\n",
    "    e_ = get(y + 0, x + 1)  # East\n",
    "    se = get(y + 1, x + 1)  # Southeast\n",
    "    s_ = get(y + 1, x + 0)  # South\n",
    "    sw = get(y + 1, x - 1)  # Southwest\n",
    "    w_ = get(y + 0, x - 1)  # West\n",
    "    nw = get(y - 1, x - 1)  # Northwest\n",
    "    \n",
    "    neighbor_states = [n_, ne, e_, se, s_, sw, w_, nw]\n",
    "    count = 0\n",
    "    for state in neighbor_states:\n",
    "        if state == ALIVE:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def game_logic(state, neighbors):\n",
    "    \"\"\"Determine next state based on current state and neighbors\"\"\"\n",
    "    if state == ALIVE:\n",
    "        if neighbors < 2:\n",
    "            return EMPTY  # Die: Too few\n",
    "        elif neighbors > 3:\n",
    "            return EMPTY  # Die: Too many\n",
    "    else:\n",
    "        if neighbors == 3:\n",
    "            return ALIVE  # Regenerate\n",
    "    return state\n",
    "\n",
    "def step_cell(y, x, get, set):\n",
    "    \"\"\"Update a single cell\"\"\"\n",
    "    state = get(y, x)\n",
    "    neighbors = count_neighbors(y, x, get)\n",
    "    next_state = game_logic(state, neighbors)\n",
    "    set(y, x, next_state)\n",
    "\n",
    "# Test neighbor counting\n",
    "neighbors = count_neighbors(2, 3, grid.get)\n",
    "print(f\"\\nCell at (2,3) has {neighbors} neighbors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-Threaded Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(grid):\n",
    "    \"\"\"Progress grid forward by one generation\"\"\"\n",
    "    next_grid = Grid(grid.height, grid.width)\n",
    "    for y in range(grid.height):\n",
    "        for x in range(grid.width):\n",
    "            step_cell(y, x, grid.get, next_grid.set)\n",
    "    return next_grid\n",
    "\n",
    "# Run simulation for 5 generations\n",
    "print(\"\\nSimulation over 5 generations:\")\n",
    "print(\"=\" * 50)\n",
    "for generation in range(5):\n",
    "    print(f\"\\nGeneration {generation}:\")\n",
    "    print(grid)\n",
    "    grid = simulate(grid)\n",
    "\n",
    "print(\"\\nNotice the glider pattern moving down and right!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem: Adding I/O\n",
    "\n",
    "**Scenario:** Need to add I/O to `game_logic` (e.g., multiplayer online game)\n",
    "\n",
    "**Challenge with blocking I/O:**\n",
    "- If I/O latency = 100ms per cell\n",
    "- Grid with 45 cells = 4.5 seconds per generation\n",
    "- Grid with 10,000 cells = 15+ minutes per generation\n",
    "\n",
    "**Solution needed:** Parallel I/O\n",
    "\n",
    "### Concurrency Concepts\n",
    "\n",
    "**Fan-out:** Spawning concurrent lines of execution for each unit of work\n",
    "\n",
    "**Fan-in:** Waiting for all concurrent units to finish before moving to next phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def game_logic_with_io(state, neighbors):\n",
    "    \"\"\"Game logic with simulated I/O\"\"\"\n",
    "    # Simulate blocking I/O\n",
    "    time.sleep(0.001)  # 1ms per cell\n",
    "    \n",
    "    if state == ALIVE:\n",
    "        if neighbors < 2:\n",
    "            return EMPTY\n",
    "        elif neighbors > 3:\n",
    "            return EMPTY\n",
    "    else:\n",
    "        if neighbors == 3:\n",
    "            return ALIVE\n",
    "    return state\n",
    "\n",
    "def simulate_with_io(grid):\n",
    "    \"\"\"Simulation with I/O delays\"\"\"\n",
    "    next_grid = Grid(grid.height, grid.width)\n",
    "    for y in range(grid.height):\n",
    "        for x in range(grid.width):\n",
    "            state = grid.get(y, x)\n",
    "            neighbors = count_neighbors(y, x, grid.get)\n",
    "            next_state = game_logic_with_io(state, neighbors)\n",
    "            next_grid.set(y, x, next_state)\n",
    "    return next_grid\n",
    "\n",
    "# Create a small grid for demo\n",
    "small_grid = Grid(3, 3)\n",
    "small_grid.set(0, 1, ALIVE)\n",
    "small_grid.set(1, 1, ALIVE)\n",
    "small_grid.set(2, 1, ALIVE)\n",
    "\n",
    "print(\"Performance with blocking I/O:\")\n",
    "print(f\"Grid size: {small_grid.height}x{small_grid.width} = {small_grid.height * small_grid.width} cells\")\n",
    "\n",
    "start = time.time()\n",
    "small_grid = simulate_with_io(small_grid)\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"Time per generation: {duration:.3f} seconds\")\n",
    "print(f\"Time per cell: {duration / (small_grid.height * small_grid.width):.4f} seconds\")\n",
    "print(\"\\nWith a 100x100 grid (10,000 cells) and 100ms I/O:\")\n",
    "print(f\"Serial execution would take: {10000 * 0.1:.0f} seconds = {10000 * 0.1 / 60:.1f} minutes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ A program often grows to require multiple concurrent lines of execution as its scope and complexity increases.\n",
    "\n",
    "✦ The most common types of concurrency coordination are fan-out (generating new units of concurrency) and fan-in (waiting for existing units of concurrency to complete).\n",
    "\n",
    "✦ Python has many different ways of achieving fan-out and fan-in.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 57: Avoid Creating New Thread Instances for On-demand Fan-out\n",
    "\n",
    "### Problems with Using Thread for Fan-out\n",
    "\n",
    "**Three major downsides:**\n",
    "\n",
    "1. **Complexity:** Threads require special coordination tools (Locks)\n",
    "2. **Memory:** ~8 MB per executing thread\n",
    "3. **Performance:** High startup cost and context switching overhead\n",
    "\n",
    "### Thread-based Solution Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock, Thread\n",
    "\n",
    "class LockingGrid(Grid):\n",
    "    \"\"\"Thread-safe Grid with locking\"\"\"\n",
    "    \n",
    "    def __init__(self, height, width):\n",
    "        super().__init__(height, width)\n",
    "        self.lock = Lock()\n",
    "    \n",
    "    def __str__(self):\n",
    "        with self.lock:\n",
    "            return super().__str__()\n",
    "    \n",
    "    def get(self, y, x):\n",
    "        with self.lock:\n",
    "            return super().get(y, x)\n",
    "    \n",
    "    def set(self, y, x, state):\n",
    "        with self.lock:\n",
    "            return super().set(y, x, state)\n",
    "\n",
    "print(\"LockingGrid adds thread safety but:\")\n",
    "print(\"1. Increased complexity (Lock overhead)\")\n",
    "print(\"2. Potential for lock contention\")\n",
    "print(\"3. Still need to create many threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threaded Simulation with Fan-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "def simulate_threaded(grid):\n",
    "    \"\"\"Simulate with one thread per cell (fan-out)\"\"\"\n",
    "    next_grid = LockingGrid(grid.height, grid.width)\n",
    "    \n",
    "    threads = []\n",
    "    for y in range(grid.height):\n",
    "        for x in range(grid.width):\n",
    "            args = (y, x, grid.get, next_grid.set)\n",
    "            thread = Thread(target=step_cell, args=args)\n",
    "            thread.start()  # Fan out\n",
    "            threads.append(thread)\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()  # Fan in\n",
    "    \n",
    "    return next_grid\n",
    "\n",
    "# Test with small grid\n",
    "grid = LockingGrid(3, 3)\n",
    "grid.set(0, 1, ALIVE)\n",
    "grid.set(1, 1, ALIVE)\n",
    "grid.set(2, 1, ALIVE)\n",
    "\n",
    "print(\"Testing threaded simulation:\")\n",
    "start = time.time()\n",
    "grid = simulate_threaded(grid)\n",
    "duration = time.time() - start\n",
    "print(f\"Time: {duration:.4f} seconds\")\n",
    "print(f\"\\nFor 10,000 cells: {10000 * 8} MB = {10000 * 8 / 1024:.1f} GB of memory!\")\n",
    "print(\"This doesn't scale!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem: Exception Handling in Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "from threading import Thread\n",
    "\n",
    "def game_logic_with_error(state, neighbors):\n",
    "    \"\"\"Game logic that raises an exception\"\"\"\n",
    "    raise OSError('Problem with I/O')\n",
    "\n",
    "# Capture stderr to see what happens\n",
    "fake_stderr = io.StringIO()\n",
    "with contextlib.redirect_stderr(fake_stderr):\n",
    "    thread = Thread(\n",
    "        target=game_logic_with_error,\n",
    "        args=(ALIVE, 3)\n",
    "    )\n",
    "    thread.start()\n",
    "    thread.join()\n",
    "\n",
    "print(\"Thread exception output:\")\n",
    "print(fake_stderr.getvalue()[:200], \"...\")\n",
    "print(\"\\nProblem: Exception is caught by Thread, not propagated!\")\n",
    "print(\"This makes debugging very difficult.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Thread Resource Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def measure_thread_overhead():\n",
    "    \"\"\"Demonstrate thread creation overhead\"\"\"\n",
    "    \n",
    "    def dummy_work():\n",
    "        time.sleep(0.001)\n",
    "    \n",
    "    # Measure thread creation time\n",
    "    num_threads = 100\n",
    "    \n",
    "    start = time.time()\n",
    "    threads = []\n",
    "    for _ in range(num_threads):\n",
    "        thread = threading.Thread(target=dummy_work)\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    duration = time.time() - start\n",
    "    \n",
    "    print(f\"Created and joined {num_threads} threads\")\n",
    "    print(f\"Total time: {duration:.3f} seconds\")\n",
    "    print(f\"Overhead per thread: {duration / num_threads * 1000:.2f} ms\")\n",
    "    print(f\"\\nFor 10,000 cells being updated 60 times/second:\")\n",
    "    print(f\"Thread creation overhead: {10000 * 60 * (duration / num_threads):.1f} seconds/second\")\n",
    "    print(\"This is clearly unsustainable!\")\n",
    "\n",
    "measure_thread_overhead()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ Threads have many downsides: They're costly to start and run if you need a lot of them, they each require a significant amount of memory, and they require special tools like `Lock` instances for coordination.\n",
    "\n",
    "✦ Threads do not provide a built-in way to raise exceptions back in the code that started a thread or that is waiting for one to finish, which makes them difficult to debug.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 58: Understand How Using Queue for Concurrency Requires Refactoring\n",
    "\n",
    "### Queue-based Pipeline Approach\n",
    "\n",
    "**Benefits over Thread per task:**\n",
    "- Fixed number of worker threads\n",
    "- Controlled resource usage\n",
    "- No repeated thread startup costs\n",
    "\n",
    "**Drawbacks:**\n",
    "- Significant refactoring required\n",
    "- More complex code\n",
    "- Manual exception handling\n",
    "- Fixed parallelism level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue-based Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from threading import Thread\n",
    "\n",
    "class ClosableQueue(Queue):\n",
    "    SENTINEL = object()\n",
    "    \n",
    "    def close(self):\n",
    "        self.put(self.SENTINEL)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            item = self.get()\n",
    "            try:\n",
    "                if item is self.SENTINEL:\n",
    "                    return\n",
    "                yield item\n",
    "            finally:\n",
    "                self.task_done()\n",
    "\n",
    "class StoppableWorker(Thread):\n",
    "    def __init__(self, func, in_queue, out_queue):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.in_queue = in_queue\n",
    "        self.out_queue = out_queue\n",
    "    \n",
    "    def run(self):\n",
    "        for item in self.in_queue:\n",
    "            result = self.func(item)\n",
    "            self.out_queue.put(result)\n",
    "\n",
    "print(\"Queue-based approach requires:\")\n",
    "print(\"1. ClosableQueue implementation\")\n",
    "print(\"2. StoppableWorker implementation\")\n",
    "print(\"3. Manual exception handling\")\n",
    "print(\"4. Complex shutdown coordination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Logic Thread Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_logic_thread(item):\n",
    "    \"\"\"Wrapper for game logic with exception handling\"\"\"\n",
    "    y, x, state, neighbors = item\n",
    "    try:\n",
    "        next_state = game_logic(state, neighbors)\n",
    "    except Exception as e:\n",
    "        next_state = e\n",
    "    return (y, x, next_state)\n",
    "\n",
    "# Create queues and workers\n",
    "in_queue = ClosableQueue()\n",
    "out_queue = ClosableQueue()\n",
    "\n",
    "threads = []\n",
    "for _ in range(5):  # Fixed number of workers\n",
    "    thread = StoppableWorker(\n",
    "        game_logic_thread,\n",
    "        in_queue,\n",
    "        out_queue\n",
    "    )\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "print(f\"Started {len(threads)} worker threads\")\n",
    "print(\"Workers wait for items on in_queue\")\n",
    "print(\"Results go to out_queue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationError(Exception):\n",
    "    pass\n",
    "\n",
    "def simulate_pipeline(grid, in_queue, out_queue):\n",
    "    \"\"\"Simulate using queue-based pipeline\"\"\"\n",
    "    # Fan out: Add all work to queue\n",
    "    for y in range(grid.height):\n",
    "        for x in range(grid.width):\n",
    "            state = grid.get(y, x)\n",
    "            neighbors = count_neighbors(y, x, grid.get)\n",
    "            in_queue.put((y, x, state, neighbors))\n",
    "    \n",
    "    # Wait for processing\n",
    "    in_queue.join()\n",
    "    out_queue.close()\n",
    "    \n",
    "    # Fan in: Collect all results\n",
    "    next_grid = Grid(grid.height, grid.width)\n",
    "    for item in out_queue:\n",
    "        y, x, next_state = item\n",
    "        if isinstance(next_state, Exception):\n",
    "            raise SimulationError(y, x) from next_state\n",
    "        next_grid.set(y, x, next_state)\n",
    "    \n",
    "    return next_grid\n",
    "\n",
    "print(\"Pipeline simulation:\")\n",
    "print(\"1. Adds all work to in_queue (fan-out)\")\n",
    "print(\"2. Workers process items in parallel\")\n",
    "print(\"3. Collects results from out_queue (fan-in)\")\n",
    "print(\"4. Propagates exceptions properly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create initial grid\n",
    "grid = Grid(5, 9)\n",
    "grid.set(0, 3, ALIVE)\n",
    "grid.set(1, 4, ALIVE)\n",
    "grid.set(2, 2, ALIVE)\n",
    "grid.set(2, 3, ALIVE)\n",
    "grid.set(2, 4, ALIVE)\n",
    "\n",
    "print(\"Initial grid:\")\n",
    "print(grid)\n",
    "\n",
    "# Run simulation\n",
    "print(\"\\nRunning 3 generations with pipeline:\")\n",
    "for generation in range(3):\n",
    "    grid = simulate_pipeline(grid, in_queue, out_queue)\n",
    "    print(f\"\\nGeneration {generation + 1}:\")\n",
    "    print(grid)\n",
    "\n",
    "# Cleanup\n",
    "for thread in threads:\n",
    "    in_queue.close()\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "print(\"\\nPipeline completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced Example: Multi-stage Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-stage pipeline for count_neighbors + game_logic\n",
    "\n",
    "def count_neighbors_thread(item):\n",
    "    \"\"\"Thread wrapper for count_neighbors\"\"\"\n",
    "    y, x, state, get = item\n",
    "    try:\n",
    "        neighbors = count_neighbors(y, x, get)\n",
    "    except Exception as e:\n",
    "        neighbors = e\n",
    "    return (y, x, state, neighbors)\n",
    "\n",
    "def game_logic_thread_v2(item):\n",
    "    \"\"\"Thread wrapper for game_logic (v2)\"\"\"\n",
    "    y, x, state, neighbors = item\n",
    "    if isinstance(neighbors, Exception):\n",
    "        next_state = neighbors\n",
    "    else:\n",
    "        try:\n",
    "            next_state = game_logic(state, neighbors)\n",
    "        except Exception as e:\n",
    "            next_state = e\n",
    "    return (y, x, next_state)\n",
    "\n",
    "# Create multi-stage pipeline\n",
    "in_queue = ClosableQueue()\n",
    "logic_queue = ClosableQueue()\n",
    "out_queue = ClosableQueue()\n",
    "\n",
    "threads = []\n",
    "\n",
    "# Stage 1: count_neighbors workers\n",
    "for _ in range(5):\n",
    "    thread = StoppableWorker(\n",
    "        count_neighbors_thread,\n",
    "        in_queue,\n",
    "        logic_queue\n",
    "    )\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "# Stage 2: game_logic workers\n",
    "for _ in range(5):\n",
    "    thread = StoppableWorker(\n",
    "        game_logic_thread_v2,\n",
    "        logic_queue,\n",
    "        out_queue\n",
    "    )\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "\n",
    "print(\"Multi-stage pipeline created:\")\n",
    "print(\"Stage 1: 5 workers for count_neighbors\")\n",
    "print(\"Stage 2: 5 workers for game_logic\")\n",
    "print(\"\\nThis allows I/O in both stages to be parallelized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Code Complexity Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nOriginal (Single-threaded):\")\n",
    "print(\"  - Grid class\")\n",
    "print(\"  - game_logic function\")\n",
    "print(\"  - simulate function\")\n",
    "print(\"  Total: ~50 lines\")\n",
    "\n",
    "print(\"\\nWith Thread per cell:\")\n",
    "print(\"  - LockingGrid class (with Lock)\")\n",
    "print(\"  - game_logic function\")\n",
    "print(\"  - simulate_threaded function\")\n",
    "print(\"  - Exception handling\")\n",
    "print(\"  Total: ~80 lines\")\n",
    "\n",
    "print(\"\\nWith Queue pipeline:\")\n",
    "print(\"  - Grid class\")\n",
    "print(\"  - ClosableQueue class\")\n",
    "print(\"  - StoppableWorker class\")\n",
    "print(\"  - game_logic_thread wrapper\")\n",
    "print(\"  - simulate_pipeline function\")\n",
    "print(\"  - Worker setup/teardown\")\n",
    "print(\"  - Exception propagation logic\")\n",
    "print(\"  Total: ~150 lines\")\n",
    "\n",
    "print(\"\\nWith Multi-stage Queue pipeline:\")\n",
    "print(\"  - All of the above, plus:\")\n",
    "print(\"  - LockingGrid (for thread safety)\")\n",
    "print(\"  - count_neighbors_thread wrapper\")\n",
    "print(\"  - Additional queue coordination\")\n",
    "print(\"  - Stage sequencing logic\")\n",
    "print(\"  Total: ~200+ lines\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Queue approach trades simplicity for:\")\n",
    "print(\"  ✓ Better resource control\")\n",
    "print(\"  ✓ No thread creation overhead\")\n",
    "print(\"  ✓ Fixed memory usage\")\n",
    "print(\"  ✗ Significant complexity increase\")\n",
    "print(\"  ✗ Manual exception handling\")\n",
    "print(\"  ✗ Rigid parallelism (fixed worker count)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Remember\n",
    "\n",
    "✦ Using `Queue` instances with a fixed number of worker threads improves the scalability of fan-out and fan-in using threads.\n",
    "\n",
    "✦ It takes a significant amount of work to refactor existing code to use `Queue`, especially when multiple stages of a pipeline are required.\n",
    "\n",
    "✦ Using `Queue` fundamentally limits the total amount of I/O parallelism a program can leverage compared to alternative approaches provided by other built-in Python features and modules.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways from Items 52-58\n",
    "\n",
    "**Item 52 - subprocess:**\n",
    "- Use `subprocess` module for child processes\n",
    "- `run()` for simple cases, `Popen` for advanced usage\n",
    "- Enables parallel CPU utilization\n",
    "\n",
    "**Item 53 - Threads and GIL:**\n",
    "- GIL prevents parallel CPU execution\n",
    "- Threads excellent for blocking I/O\n",
    "- Not suitable for CPU-bound parallelism\n",
    "\n",
    "**Item 54 - Lock:**\n",
    "- GIL doesn't protect from data races\n",
    "- Use `Lock` for thread synchronization\n",
    "- Critical for shared mutable state\n",
    "\n",
    "**Item 55 - Queue:**\n",
    "- Coordinate work between threads\n",
    "- Eliminates busy waiting\n",
    "- Provides buffer management and joining\n",
    "\n",
    "**Item 56 - Recognizing Concurrency:**\n",
    "- Fan-out: spawn concurrent execution\n",
    "- Fan-in: wait for completion\n",
    "- Critical for I/O-heavy applications\n",
    "\n",
    "**Item 57 - Avoid Thread Per Task:**\n",
    "- High memory cost (~8MB/thread)\n",
    "- Startup overhead\n",
    "- Poor exception propagation\n",
    "\n",
    "**Item 58 - Queue Refactoring:**\n",
    "- Fixed worker pool better than thread-per-task\n",
    "- Requires significant refactoring\n",
    "- Trade-off: complexity vs scalability\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In Part 2, we'll cover:\n",
    "- Item 59: ThreadPoolExecutor\n",
    "- Item 60: Coroutines for I/O\n",
    "- Item 61+: Advanced concurrency patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
