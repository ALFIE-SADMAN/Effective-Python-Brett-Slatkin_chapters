{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Profiling and Performance Optimization\n",
    "\n",
    "## Chapter 8: Robustness and Performance\n",
    "\n",
    "This notebook covers key concepts from Effective Python regarding profiling and optimizing Python code performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Item 70: Profile Before Optimizing\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "The dynamic nature of Python causes surprising performance behaviors:\n",
    "- Operations you assume are slow may be fast (string manipulation, generators)\n",
    "- Operations you assume are fast may be slow (attribute access, function calls)\n",
    "- The true source of slowdowns can be obscure\n",
    "\n",
    "**Best Practice:** Ignore intuition and directly measure performance before optimizing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Profiling an Insertion Sort\n",
    "\n",
    "Let's profile a simple insertion sort algorithm to identify performance bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(data):\n",
    "    \"\"\"Sort a list using insertion sort algorithm.\"\"\"\n",
    "    result = []\n",
    "    for value in data:\n",
    "        insert_value(result, value)\n",
    "    return result\n",
    "\n",
    "def insert_value(array, value):\n",
    "    \"\"\"Insert value into sorted array (inefficient linear scan version).\"\"\"\n",
    "    for i, existing in enumerate(array):\n",
    "        if existing > value:\n",
    "            array.insert(i, value)\n",
    "            return\n",
    "    array.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from cProfile import Profile\n",
    "from pstats import Stats\n",
    "\n",
    "# Create test data\n",
    "max_size = 10**4\n",
    "data = [randint(0, max_size) for _ in range(max_size)]\n",
    "test = lambda: insertion_sort(data)\n",
    "\n",
    "# Run the profiler\n",
    "profiler = Profile()\n",
    "profiler.runcall(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Profiler Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display statistics\n",
    "stats = Stats(profiler)\n",
    "stats.strip_dirs()\n",
    "stats.sort_stats('cumulative')\n",
    "stats.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Profiler Columns\n",
    "\n",
    "- **ncalls**: Number of calls to the function during profiling\n",
    "- **tottime**: Seconds spent in the function (excluding other function calls)\n",
    "- **tottime percall**: Average time per call (tottime / ncalls)\n",
    "- **cumtime**: Cumulative time spent in the function (including other function calls)\n",
    "- **cumtime percall**: Average cumulative time per call (cumtime / ncalls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing with bisect Module\n",
    "\n",
    "After profiling reveals `insert_value` is the bottleneck, we can optimize it using binary search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def insert_value_optimized(array, value):\n",
    "    \"\"\"Insert value using binary search (much faster).\"\"\"\n",
    "    i = bisect_left(array, value)\n",
    "    array.insert(i, value)\n",
    "\n",
    "# Profile again with optimized version\n",
    "def insertion_sort_optimized(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        insert_value_optimized(result, value)\n",
    "    return result\n",
    "\n",
    "test_optimized = lambda: insertion_sort_optimized(data)\n",
    "profiler_optimized = Profile()\n",
    "profiler_optimized.runcall(test_optimized)\n",
    "\n",
    "stats_optimized = Stats(profiler_optimized)\n",
    "stats_optimized.strip_dirs()\n",
    "stats_optimized.sort_stats('cumulative')\n",
    "stats_optimized.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using print_callers for Call Analysis\n",
    "\n",
    "When a utility function is called from multiple places, use `print_callers()` to identify which callers contribute most to execution time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_utility(a, b):\n",
    "    \"\"\"Example utility function.\"\"\"\n",
    "    c = 1\n",
    "    for i in range(100):\n",
    "        c += a * b\n",
    "    return c\n",
    "\n",
    "def first_func():\n",
    "    \"\"\"Calls my_utility many times.\"\"\"\n",
    "    for _ in range(1000):\n",
    "        my_utility(4, 5)\n",
    "\n",
    "def second_func():\n",
    "    \"\"\"Calls my_utility fewer times.\"\"\"\n",
    "    for _ in range(10):\n",
    "        my_utility(1, 3)\n",
    "\n",
    "def my_program():\n",
    "    \"\"\"Main program calling both functions.\"\"\"\n",
    "    for _ in range(20):\n",
    "        first_func()\n",
    "        second_func()\n",
    "\n",
    "# Profile and analyze callers\n",
    "profiler = Profile()\n",
    "profiler.runcall(my_program)\n",
    "stats = Stats(profiler)\n",
    "stats.print_callers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Item 71: Prefer deque for Producer-Consumer Queues\n",
    "\n",
    "### The Problem with list as a FIFO Queue\n",
    "\n",
    "Using `list.pop(0)` for FIFO queues has **quadratic time complexity** because it requires moving all remaining elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Email processing queue (problematic implementation)\n",
    "class Email:\n",
    "    def __init__(self, sender, receiver, message):\n",
    "        self.sender = sender\n",
    "        self.receiver = receiver\n",
    "        self.message = message\n",
    "\n",
    "def produce_emails(queue):\n",
    "    \"\"\"Producer: adds emails to queue.\"\"\"\n",
    "    # Simulated email receiving\n",
    "    pass\n",
    "\n",
    "def consume_one_email_slow(queue):\n",
    "    \"\"\"Consumer: processes one email (slow with list).\"\"\"\n",
    "    if not queue:\n",
    "        return\n",
    "    email = queue.pop(0)  # O(n) operation!\n",
    "    # Process email..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Benchmark: list.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "def print_results(count, tests):\n",
    "    avg_iteration = sum(tests) / len(tests)\n",
    "    print(f'Count {count:>5,} takes {avg_iteration:.6f}s')\n",
    "    return count, avg_iteration\n",
    "\n",
    "def print_delta(before, after):\n",
    "    before_count, before_time = before\n",
    "    after_count, after_time = after\n",
    "    growth = 1 + (after_count - before_count) / before_count\n",
    "    slowdown = 1 + (after_time - before_time) / before_time\n",
    "    print(f'{growth:>4.1f}x data size, {slowdown:>4.1f}x time')\n",
    "\n",
    "def list_pop_benchmark(count):\n",
    "    def prepare():\n",
    "        return list(range(count))\n",
    "    \n",
    "    def run(queue):\n",
    "        while queue:\n",
    "            queue.pop(0)\n",
    "    \n",
    "    tests = timeit.repeat(\n",
    "        setup='queue = prepare()',\n",
    "        stmt='run(queue)',\n",
    "        globals=locals(),\n",
    "        repeat=1000,\n",
    "        number=1)\n",
    "    return print_results(count, tests)\n",
    "\n",
    "# Run benchmarks\n",
    "baseline = list_pop_benchmark(500)\n",
    "for count in (1_000, 2_000, 3_000, 4_000, 5_000):\n",
    "    comparison = list_pop_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Using collections.deque\n",
    "\n",
    "The `deque` class provides **constant-time** operations for both ends of the queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def consume_one_email_fast(queue):\n",
    "    \"\"\"Consumer: processes one email (fast with deque).\"\"\"\n",
    "    if not queue:\n",
    "        return\n",
    "    email = queue.popleft()  # O(1) operation!\n",
    "    # Process email...\n",
    "\n",
    "# Initialize queue with deque\n",
    "queue = collections.deque()\n",
    "\n",
    "# Producer still uses append (same as list)\n",
    "# queue.append(email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Benchmark: deque.popleft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deque_popleft_benchmark(count):\n",
    "    def prepare():\n",
    "        return collections.deque(range(count))\n",
    "    \n",
    "    def run(queue):\n",
    "        while queue:\n",
    "            queue.popleft()\n",
    "    \n",
    "    tests = timeit.repeat(\n",
    "        setup='queue = prepare()',\n",
    "        stmt='run(queue)',\n",
    "        globals=locals(),\n",
    "        repeat=1000,\n",
    "        number=1)\n",
    "    return print_results(count, tests)\n",
    "\n",
    "# Run benchmarks\n",
    "baseline = deque_popleft_benchmark(500)\n",
    "for count in (1_000, 2_000, 3_000, 4_000, 5_000):\n",
    "    comparison = deque_popleft_benchmark(count)\n",
    "    print_delta(baseline, comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Item 72: Consider Searching Sorted Sequences with bisect\n",
    "\n",
    "### The Problem: Linear Search\n",
    "\n",
    "Searching for values in a sorted list using `list.index()` takes **linear time** O(n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear search example\n",
    "data = list(range(10**5))\n",
    "index = data.index(91234)\n",
    "print(f\"Found at index: {index}\")\n",
    "\n",
    "# Finding closest value (linear scan)\n",
    "def find_closest_linear(sequence, goal):\n",
    "    \"\"\"Find index where goal should be inserted (O(n)).\"\"\"\n",
    "    for index, value in enumerate(sequence):\n",
    "        if goal < value:\n",
    "            return index\n",
    "    raise ValueError(f'{goal} is out of bounds')\n",
    "\n",
    "index = find_closest_linear(data, 91234.56)\n",
    "print(f\"Closest index: {index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Binary Search with bisect\n",
    "\n",
    "The `bisect` module provides **logarithmic time** O(log n) binary search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "# Exact match\n",
    "index = bisect_left(data, 91234)\n",
    "print(f\"Exact match at: {index}\")\n",
    "assert index == 91234\n",
    "\n",
    "# Closest match\n",
    "index = bisect_left(data, 91234.56)\n",
    "print(f\"Closest match at: {index}\")\n",
    "assert index == 91235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "size = 10**5\n",
    "iterations = 1000\n",
    "data = list(range(size))\n",
    "to_lookup = [random.randint(0, size) for _ in range(iterations)]\n",
    "\n",
    "def run_linear(data, to_lookup):\n",
    "    for index in to_lookup:\n",
    "        data.index(index)\n",
    "\n",
    "def run_bisect(data, to_lookup):\n",
    "    for index in to_lookup:\n",
    "        bisect_left(data, index)\n",
    "\n",
    "# Benchmark linear search\n",
    "baseline = timeit.timeit(\n",
    "    stmt='run_linear(data, to_lookup)',\n",
    "    globals=globals(),\n",
    "    number=10)\n",
    "print(f'Linear search takes {baseline:.6f}s')\n",
    "\n",
    "# Benchmark bisect\n",
    "comparison = timeit.timeit(\n",
    "    stmt='run_bisect(data, to_lookup)',\n",
    "    globals=globals(),\n",
    "    number=10)\n",
    "print(f'Bisect search takes {comparison:.6f}s')\n",
    "\n",
    "slowdown = 1 + ((baseline - comparison) / comparison)\n",
    "print(f'{slowdown:.1f}x speedup with bisect')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Item 73: Know How to Use heapq for Priority Queues\n",
    "\n",
    "### The Problem: Maintaining Priority Order\n",
    "\n",
    "FIFO queues process items in arrival order, but sometimes you need to process by **priority** (importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Library book due dates\n",
    "class Book:\n",
    "    def __init__(self, title, due_date):\n",
    "        self.title = title\n",
    "        self.due_date = due_date\n",
    "\n",
    "# Naive approach: sort entire list every time (expensive!)\n",
    "def add_book_slow(queue, book):\n",
    "    queue.append(book)\n",
    "    queue.sort(key=lambda x: x.due_date, reverse=True)  # O(n log n)\n",
    "\n",
    "class NoOverdueBooks(Exception):\n",
    "    pass\n",
    "\n",
    "def next_overdue_book_slow(queue, now):\n",
    "    if queue:\n",
    "        book = queue[-1]\n",
    "        if book.due_date < now:\n",
    "            queue.pop()\n",
    "            return book\n",
    "    raise NoOverdueBooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Using heapq Module\n",
    "\n",
    "A **heap** provides **logarithmic time** O(log n) for insertions and removals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop, heapify\n",
    "import functools\n",
    "\n",
    "# Books must be comparable for heapq\n",
    "@functools.total_ordering\n",
    "class Book:\n",
    "    def __init__(self, title, due_date):\n",
    "        self.title = title\n",
    "        self.due_date = due_date\n",
    "        self.returned = False\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.due_date < other.due_date\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Book('{self.title}', '{self.due_date}')\"\n",
    "\n",
    "# Fast priority queue operations\n",
    "def add_book_fast(queue, book):\n",
    "    heappush(queue, book)  # O(log n)\n",
    "\n",
    "def next_overdue_book_fast(queue, now):\n",
    "    while queue:\n",
    "        book = queue[0]  # Peek at highest priority\n",
    "        if book.returned:\n",
    "            heappop(queue)  # Remove returned books\n",
    "            continue\n",
    "        if book.due_date < now:\n",
    "            heappop(queue)  # O(log n)\n",
    "            return book\n",
    "        break\n",
    "    raise NoOverdueBooks\n",
    "\n",
    "def return_book(queue, book):\n",
    "    \"\"\"Mark book as returned (no queue modification needed).\"\"\"\n",
    "    book.returned = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using heapq: Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create priority queue\n",
    "queue = []\n",
    "add_book_fast(queue, Book('Pride and Prejudice', '2019-06-01'))\n",
    "add_book_fast(queue, Book('The Time Machine', '2019-05-30'))\n",
    "add_book_fast(queue, Book('Crime and Punishment', '2019-06-06'))\n",
    "add_book_fast(queue, Book('Wuthering Heights', '2019-06-12'))\n",
    "\n",
    "print(\"Books in priority order:\")\n",
    "for book in sorted(queue):\n",
    "    print(f\"  {book}\")\n",
    "\n",
    "# Alternative: create heap from existing list\n",
    "queue2 = [\n",
    "    Book('Book A', '2019-06-01'),\n",
    "    Book('Book B', '2019-05-30'),\n",
    "    Book('Book C', '2019-06-06'),\n",
    "]\n",
    "heapify(queue2)  # O(n) - faster than sorting O(n log n)\n",
    "\n",
    "# Process overdue books\n",
    "now = '2019-06-02'\n",
    "try:\n",
    "    book = next_overdue_book_fast(queue, now)\n",
    "    print(f\"\\nOverdue: {book.title}\")\n",
    "    book = next_overdue_book_fast(queue, now)\n",
    "    print(f\"Overdue: {book.title}\")\n",
    "except NoOverdueBooks:\n",
    "    print(\"No more overdue books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Item 74: Consider memoryview and bytearray for Zero-Copy Interactions\n",
    "\n",
    "### The Problem: Copying Overhead\n",
    "\n",
    "Slicing `bytes` creates a **copy** of the data, which can be expensive for large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Video streaming server\n",
    "# Naive approach with copying\n",
    "video_data = b'x' * (1024 * 1024 * 100)  # 100 MB\n",
    "byte_offset = 1024 * 1024 * 50\n",
    "size = 20 * 1024 * 1024  # 20 MB chunk\n",
    "\n",
    "def send_chunk_with_copy():\n",
    "    chunk = video_data[byte_offset:byte_offset + size]  # Copies data!\n",
    "    # socket.send(chunk)\n",
    "    return chunk\n",
    "\n",
    "# Benchmark the copy operation\n",
    "result = timeit.timeit(\n",
    "    'send_chunk_with_copy()',\n",
    "    globals=globals(),\n",
    "    number=100) / 100\n",
    "print(f'Slice with copy: {result:.9f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Zero-Copy with memoryview\n",
    "\n",
    "The `memoryview` type provides access to buffer protocol for **zero-copy** slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-copy approach\n",
    "video_view = memoryview(video_data)\n",
    "\n",
    "def send_chunk_zero_copy():\n",
    "    chunk = video_view[byte_offset:byte_offset + size]  # No copy!\n",
    "    # socket.send(chunk)\n",
    "    return chunk\n",
    "\n",
    "# Benchmark zero-copy\n",
    "result = timeit.timeit(\n",
    "    'send_chunk_zero_copy()',\n",
    "    globals=globals(),\n",
    "    number=100) / 100\n",
    "print(f'Slice with memoryview: {result:.9f} seconds')\n",
    "\n",
    "# Inspect memoryview\n",
    "data = b'shave and a haircut, two bits'\n",
    "view = memoryview(data)\n",
    "chunk = view[12:19]\n",
    "print(f\"\\nMemoryview: {chunk}\")\n",
    "print(f\"Size: {chunk.nbytes}\")\n",
    "print(f\"Data in view: {chunk.tobytes()}\")\n",
    "print(f\"Underlying data: {chunk.obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable Buffer Operations with bytearray\n",
    "\n",
    "For receiving data, use `bytearray` (mutable) with `memoryview` for in-place updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bytes is immutable\n",
    "my_bytes = b'hello'\n",
    "try:\n",
    "    my_bytes[0] = 0x79\n",
    "except TypeError as e:\n",
    "    print(f\"bytes error: {e}\")\n",
    "\n",
    "# bytearray is mutable\n",
    "my_array = bytearray(b'hello')\n",
    "my_array[0] = 0x79\n",
    "print(f\"\\nMutable bytearray: {my_array}\")\n",
    "\n",
    "# memoryview + bytearray for zero-copy writes\n",
    "my_array = bytearray(b'row, row, row your boat')\n",
    "my_view = memoryview(my_array)\n",
    "write_view = my_view[3:13]\n",
    "write_view[:] = b'-10 bytes-'\n",
    "print(f\"After write: {my_array}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using socket.recv_into for Zero-Copy Receives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: receiving video stream data\n",
    "video_cache = b'x' * (1024 * 1024 * 100)  # 100 MB cache\n",
    "video_array = bytearray(video_cache)\n",
    "write_view = memoryview(video_array)\n",
    "byte_offset = 1024 * 1024 * 50\n",
    "size = 1024 * 1024  # 1 MB chunk\n",
    "\n",
    "# Slow approach: recv + splicing\n",
    "def receive_with_copy(socket):\n",
    "    chunk = socket.recv(size)  # Allocates new bytes\n",
    "    before = video_view[:byte_offset]\n",
    "    after = video_view[byte_offset + size:]\n",
    "    new_cache = b''.join([before, chunk, after])  # Expensive!\n",
    "    return new_cache\n",
    "\n",
    "# Fast approach: recv_into with memoryview\n",
    "def receive_zero_copy(socket):\n",
    "    chunk = write_view[byte_offset:byte_offset + size]\n",
    "    socket.recv_into(chunk)  # Writes directly to buffer!\n",
    "    # No splicing needed\n",
    "\n",
    "print(\"Zero-copy receiving provides massive performance improvements!\")\n",
    "print(\"- Eliminates memory allocation\")\n",
    "print(\"- Eliminates data copying\")\n",
    "print(\"- Enables high-throughput I/O operations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Performance Best Practices\n",
    "\n",
    "### Profiling\n",
    "1. **Always profile before optimizing** - don't trust intuition\n",
    "2. Use `cProfile` for accurate profiling (not `profile`)\n",
    "3. Use `pstats.Stats` to analyze profiler output\n",
    "4. Use `print_callers()` to identify which call sites contribute most\n",
    "\n",
    "### Data Structures\n",
    "1. **Use `collections.deque`** for FIFO queues (not `list`)\n",
    "   - `list.pop(0)` is O(n)\n",
    "   - `deque.popleft()` is O(1)\n",
    "\n",
    "2. **Use `bisect`** for searching sorted sequences\n",
    "   - `list.index()` is O(n)\n",
    "   - `bisect_left()` is O(log n)\n",
    "\n",
    "3. **Use `heapq`** for priority queues\n",
    "   - `list.sort()` is O(n log n)\n",
    "   - `heappush()`/`heappop()` are O(log n)\n",
    "\n",
    "### Memory Optimization\n",
    "1. **Use `memoryview`** for zero-copy slicing of bytes\n",
    "2. **Use `bytearray`** with `memoryview` for mutable buffers\n",
    "3. **Use buffer protocol methods** like `socket.recv_into()`\n",
    "\n",
    "### Key Takeaways\n",
    "- **Measure, don't guess**: Profile to identify real bottlenecks\n",
    "- **Choose the right data structure**: Can change O(nÂ²) to O(n log n) or O(n)\n",
    "- **Avoid unnecessary copies**: Zero-copy operations are dramatically faster\n",
    "- **Understand complexity**: Know the Big-O behavior of your operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
