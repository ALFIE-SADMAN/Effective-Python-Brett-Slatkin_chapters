{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8: Robustness and Performance in Python\n",
    "\n",
    "This notebook covers essential patterns and practices for writing robust, maintainable Python code with optimal performance characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 65: Take Advantage of Each Block in try/except/else/finally\n",
    "\n",
    "Python's exception handling constructs provide four distinct blocks, each serving specific purposes in error management and resource cleanup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The finally Block\n",
    "\n",
    "The `finally` block executes cleanup code regardless of whether exceptions occur. This ensures resources are properly released even when errors arise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_finally_example(filename):\n",
    "    print('* Opening file')\n",
    "    handle = open(filename, encoding='utf-8')  # Maybe OSError\n",
    "    try:\n",
    "        print('* Reading data')\n",
    "        return handle.read()  # Maybe UnicodeDecodeError\n",
    "    finally:\n",
    "        print('* Calling close()')\n",
    "        handle.close()  # Always runs after try block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `finally` block executes even when exceptions propagate upward. This demonstrates proper resource cleanup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test file with invalid UTF-8 data\n",
    "filename = 'random_data.txt'\n",
    "with open(filename, 'wb') as f:\n",
    "    f.write(b'\\xf1\\xf2\\xf3\\xf4\\xf5')  # Invalid utf-8\n",
    "\n",
    "try:\n",
    "    data = try_finally_example(filename)\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"\\nCaught exception: {e.__class__.__name__}\")\n",
    "    print(\"Notice that close() was called before the exception propagated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the file doesn't exist, the `finally` block is skipped entirely because `open()` occurs before the try block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    try_finally_example('does_not_exist.txt')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Caught: {e.__class__.__name__}\")\n",
    "    print(\"The finally block never executed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The else Block\n",
    "\n",
    "The `else` block executes when the try block succeeds without exceptions. This clarifies exception handling boundaries and isolates potential error sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_json_key(data, key):\n",
    "    try:\n",
    "        print('* Loading JSON data')\n",
    "        result_dict = json.loads(data)  # May raise ValueError\n",
    "    except ValueError as e:\n",
    "        print('* Handling ValueError')\n",
    "        raise KeyError(key) from e\n",
    "    else:\n",
    "        print('* Looking up key')\n",
    "        return result_dict[key]  # May raise KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the successful case, both the try and else blocks execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = load_json_key('{\"foo\": \"bar\"}', 'foo')\n",
    "print(f\"\\nResult: {result}\")\n",
    "assert result == 'bar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When JSON decoding fails, the except block handles the error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    load_json_key('{\"foo\": bad payload', 'foo')\n",
    "except KeyError as e:\n",
    "    print(f\"\\nCaught KeyError: {e}\")\n",
    "    print(\"The ValueError was transformed into a KeyError\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key lookup failures in the else block propagate naturally without special handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    load_json_key('{\"foo\": \"bar\"}', 'does not exist')\n",
    "except KeyError as e:\n",
    "    print(f\"Caught KeyError from else block: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everything Together: try/except/else/finally\n",
    "\n",
    "Combining all four blocks provides comprehensive error handling for complex operations requiring setup, processing, success actions, and cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNDEFINED = object()\n",
    "\n",
    "def divide_json(path):\n",
    "    print('* Opening file')\n",
    "    handle = open(path, 'r+')  # May raise OSError\n",
    "    try:\n",
    "        print('* Reading data')\n",
    "        data = handle.read()  # May raise UnicodeDecodeError\n",
    "        print('* Loading JSON data')\n",
    "        op = json.loads(data)  # May raise ValueError\n",
    "        print('* Performing calculation')\n",
    "        value = (\n",
    "            op['numerator'] /\n",
    "            op['denominator'])  # May raise ZeroDivisionError\n",
    "    except ZeroDivisionError as e:\n",
    "        print('* Handling ZeroDivisionError')\n",
    "        return UNDEFINED\n",
    "    else:\n",
    "        print('* Writing calculation')\n",
    "        op['result'] = value\n",
    "        result = json.dumps(op)\n",
    "        handle.seek(0)  # May raise OSError\n",
    "        handle.write(result)  # May raise OSError\n",
    "        return value\n",
    "    finally:\n",
    "        print('* Calling close()')\n",
    "        handle.close()  # Always runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successful execution path (try → else → finally):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = 'random_data.json'\n",
    "\n",
    "with open(temp_path, 'w') as f:\n",
    "    f.write('{\"numerator\": 1, \"denominator\": 10}')\n",
    "\n",
    "result = divide_json(temp_path)\n",
    "print(f\"\\nResult: {result}\")\n",
    "assert result == 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handled exception path (try → except → finally, skipping else):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_path, 'w') as f:\n",
    "    f.write('{\"numerator\": 1, \"denominator\": 0}')\n",
    "\n",
    "result = divide_json(temp_path)\n",
    "print(f\"\\nResult is UNDEFINED: {result is UNDEFINED}\")\n",
    "assert result is UNDEFINED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unhandled exception path (try → finally → exception propagates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(temp_path, 'w') as f:\n",
    "    f.write('{\"numerator\": 1 bad data')\n",
    "\n",
    "try:\n",
    "    divide_json(temp_path)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\nCaught {e.__class__.__name__}\")\n",
    "    print(\"Notice that close() was called before exception propagated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exception in else block still triggers finally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This would simulate disk full error during write in else block\n",
    "# The finally block would still execute to close the file handle\n",
    "print(\"The finally block ensures cleanup even when else block fails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Principles\n",
    "\n",
    "**try block**: Contains code that might raise exceptions you want to handle\n",
    "\n",
    "**except block**: Handles specific exceptions from the try block\n",
    "\n",
    "**else block**: Executes only on try block success, before finally. Isolates success-case logic from exception-prone code\n",
    "\n",
    "**finally block**: Always executes for cleanup, regardless of exceptions. Runs after try, except, and else blocks complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 66: Consider contextlib and with Statements for Reusable try/finally Behavior\n",
    "\n",
    "Context managers abstract try/finally patterns into reusable constructs. The `with` statement provides syntactic sugar for context management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic with Statement Usage\n",
    "\n",
    "The with statement replaces explicit try/finally constructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Lock\n",
    "\n",
    "lock = Lock()\n",
    "\n",
    "# Modern approach with 'with'\n",
    "with lock:\n",
    "    print(\"This code runs while holding the lock\")\n",
    "\n",
    "print(\"\\nEquivalent to:\")\n",
    "\n",
    "# Traditional approach\n",
    "lock.acquire()\n",
    "try:\n",
    "    print(\"This code runs while holding the lock\")\n",
    "finally:\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Context Managers with contextlib\n",
    "\n",
    "The `contextmanager` decorator transforms generator functions into context managers without requiring `__enter__` and `__exit__` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from contextlib import contextmanager\n",
    "\n",
    "def my_function():\n",
    "    logging.debug('Some debug data')\n",
    "    logging.error('Error log here')\n",
    "    logging.debug('More debug data')\n",
    "\n",
    "@contextmanager\n",
    "def debug_logging(level):\n",
    "    logger = logging.getLogger()\n",
    "    old_level = logger.getEffectiveLevel()\n",
    "    logger.setLevel(level)\n",
    "    try:\n",
    "        yield  # Point where 'with' block executes\n",
    "    finally:\n",
    "        logger.setLevel(old_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context manager temporarily modifies logging levels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default logging level is WARNING\n",
    "print(\"Outside debug context:\")\n",
    "my_function()\n",
    "\n",
    "print(\"\\nInside debug context:\")\n",
    "with debug_logging(logging.DEBUG):\n",
    "    my_function()\n",
    "\n",
    "print(\"\\nAfter debug context:\")\n",
    "my_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using with Targets\n",
    "\n",
    "Context managers can yield values that become available via the `as` clause:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File handling with context manager\n",
    "with open('my_output.txt', 'w') as handle:\n",
    "    handle.write('This is some data!')\n",
    "\n",
    "print(\"File was automatically closed after with block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating custom context managers that yield values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def log_level(level, name):\n",
    "    logger = logging.getLogger(name)\n",
    "    old_level = logger.getEffectiveLevel()\n",
    "    logger.setLevel(level)\n",
    "    try:\n",
    "        yield logger  # Provides logger as target\n",
    "    finally:\n",
    "        logger.setLevel(old_level)\n",
    "\n",
    "with log_level(logging.DEBUG, 'my-log') as logger:\n",
    "    logger.debug(f'This is a message for {logger.name}!')\n",
    "    logging.debug('This will not print')  # Default logger still at WARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After exiting the context, the logger returns to its default level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('my-log')\n",
    "logger.debug('Debug will not print')\n",
    "logger.error('Error will print')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context managers provide state isolation by decoupling context creation from context usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with log_level(logging.DEBUG, 'other-log') as logger:\n",
    "    logger.debug(f'This is a message for {logger.name}!')\n",
    "    logging.debug('This will not print')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 67: Use datetime Instead of time for Local Clocks\n",
    "\n",
    "Python provides two approaches for time zone conversions. The `time` module is platform-dependent and error-prone. The `datetime` module with `pytz` provides reliable cross-platform time zone handling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The time Module (Avoid)\n",
    "\n",
    "The `time` module converts between UTC timestamps and local time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "now = 1552774475\n",
    "local_tuple = time.localtime(now)\n",
    "time_format = '%Y-%m-%d %H:%M:%S'\n",
    "time_str = time.strftime(time_format, local_tuple)\n",
    "print(f\"Local time: {time_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting back from local time to UTC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_tuple = time.strptime(time_str, time_format)\n",
    "utc_now = time.mktime(time_tuple)\n",
    "print(f\"UTC timestamp: {utc_now}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `time` module has severe platform-dependent limitations. Time zone support varies by operating system, making it unreliable for cross-platform applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The datetime Module (Recommended)\n",
    "\n",
    "The `datetime` module provides consistent time zone operations across platforms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "now = datetime(2019, 3, 16, 22, 14, 35)\n",
    "now_utc = now.replace(tzinfo=timezone.utc)\n",
    "now_local = now_utc.astimezone()\n",
    "print(f\"Local time: {now_local}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting local time back to UTC timestamp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_str = '2019-03-16 15:14:35'\n",
    "now = datetime.strptime(time_str, time_format)\n",
    "time_tuple = now.timetuple()\n",
    "utc_now = time.mktime(time_tuple)\n",
    "print(f\"UTC timestamp: {utc_now}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Multiple Time Zones Using pytz\n",
    "\n",
    "The `pytz` library provides comprehensive time zone support. Always convert to UTC first, perform operations, then convert to local time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pytz\n",
    "    \n",
    "    # Convert NYC time to UTC\n",
    "    arrival_nyc = '2019-03-16 23:33:24'\n",
    "    nyc_dt_naive = datetime.strptime(arrival_nyc, time_format)\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    nyc_dt = eastern.localize(nyc_dt_naive)\n",
    "    utc_dt = pytz.utc.normalize(nyc_dt.astimezone(pytz.utc))\n",
    "    print(f\"UTC time: {utc_dt}\")\n",
    "    \n",
    "    # Convert UTC to San Francisco time\n",
    "    pacific = pytz.timezone('US/Pacific')\n",
    "    sf_dt = pacific.normalize(utc_dt.astimezone(pacific))\n",
    "    print(f\"San Francisco time: {sf_dt}\")\n",
    "    \n",
    "    # Convert UTC to Nepal time\n",
    "    nepal = pytz.timezone('Asia/Katmandu')\n",
    "    nepal_dt = nepal.normalize(utc_dt.astimezone(nepal))\n",
    "    print(f\"Nepal time: {nepal_dt}\")\n",
    "    \nexcept ImportError:\n",
    "    print(\"pytz not installed. Install with: pip install pytz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices for Time Zone Handling\n",
    "\n",
    "**Always use UTC internally**: Store and process all times in UTC\n",
    "\n",
    "**Convert to local time only for display**: Perform the conversion as the final step before presentation\n",
    "\n",
    "**Use datetime with pytz**: Avoid the `time` module for anything beyond simple UTC to local conversions\n",
    "\n",
    "**Follow the conversion pattern**: Local → UTC → Operations → UTC → Local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 68: Make pickle Reliable with copyreg\n",
    "\n",
    "The `pickle` module serializes Python objects but has limitations when class definitions change. The `copyreg` module provides mechanisms for backward-compatible serialization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic pickle Usage\n",
    "\n",
    "Pickle serializes object state for later reconstruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class GameState:\n",
    "    def __init__(self):\n",
    "        self.level = 0\n",
    "        self.lives = 4\n",
    "\n",
    "state = GameState()\n",
    "state.level += 1\n",
    "state.lives -= 1\n",
    "print(f\"Original state: {state.__dict__}\")\n",
    "\n",
    "# Serialize to file\n",
    "state_path = 'game_state.bin'\n",
    "with open(state_path, 'wb') as f:\n",
    "    pickle.dump(state, f)\n",
    "\n",
    "# Deserialize from file\n",
    "with open(state_path, 'rb') as f:\n",
    "    state_after = pickle.load(f)\n",
    "print(f\"Restored state: {state_after.__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem: Adding Fields\n",
    "\n",
    "When you add fields to a class, old pickled objects lack those attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self):\n",
    "        self.level = 0\n",
    "        self.lives = 4\n",
    "        self.points = 0  # New field\n",
    "\n",
    "# Serialize with new definition\n",
    "state = GameState()\n",
    "serialized = pickle.dumps(state)\n",
    "state_after = pickle.loads(serialized)\n",
    "print(f\"New serialization: {state_after.__dict__}\")\n",
    "\n",
    "# But old pickled data is missing the new field\n",
    "with open(state_path, 'rb') as f:\n",
    "    state_after = pickle.load(f)\n",
    "print(f\"Old serialization: {state_after.__dict__}\")\n",
    "print(f\"Missing 'points' field: {'points' not in state_after.__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Default Attribute Values with copyreg\n",
    "\n",
    "Use constructor default arguments to ensure all attributes exist after unpickling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copyreg\n",
    "\n",
    "class GameState:\n",
    "    def __init__(self, level=0, lives=4, points=0):\n",
    "        self.level = level\n",
    "        self.lives = lives\n",
    "        self.points = points\n",
    "\n",
    "def pickle_game_state(game_state):\n",
    "    kwargs = game_state.__dict__\n",
    "    return unpickle_game_state, (kwargs,)\n",
    "\n",
    "def unpickle_game_state(kwargs):\n",
    "    return GameState(**kwargs)\n",
    "\n",
    "copyreg.pickle(GameState, pickle_game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now serialization preserves all attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = GameState()\n",
    "state.points += 1000\n",
    "serialized = pickle.dumps(state)\n",
    "state_after = pickle.loads(serialized)\n",
    "print(f\"Serialized state: {state_after.__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding new fields works seamlessly with default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, level=0, lives=4, points=0, magic=5):\n",
    "        self.level = level\n",
    "        self.lives = lives\n",
    "        self.points = points\n",
    "        self.magic = magic  # New field\n",
    "\n",
    "# Old serialized data gets default value for new field\n",
    "state_after = pickle.loads(serialized)\n",
    "print(f\"Old data with new field: {state_after.__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versioning Classes\n",
    "\n",
    "For backward-incompatible changes like removing fields, use version numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameState:\n",
    "    def __init__(self, level=0, points=0, magic=5):\n",
    "        self.level = level\n",
    "        self.points = points\n",
    "        self.magic = magic\n",
    "        # Removed 'lives' field\n",
    "\n",
    "def pickle_game_state(game_state):\n",
    "    kwargs = game_state.__dict__\n",
    "    kwargs['version'] = 2  # Mark as version 2\n",
    "    return unpickle_game_state, (kwargs,)\n",
    "\n",
    "def unpickle_game_state(kwargs):\n",
    "    version = kwargs.pop('version', 1)\n",
    "    if version == 1:\n",
    "        del kwargs['lives']  # Remove obsolete field\n",
    "    return GameState(**kwargs)\n",
    "\n",
    "copyreg.pickle(GameState, pickle_game_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old data deserializes successfully by removing obsolete fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deserialize old version 1 data\n",
    "state_after = pickle.loads(serialized)\n",
    "print(f\"Version 1 data migrated: {state_after.__dict__}\")\n",
    "print(f\"'lives' field removed: {'lives' not in state_after.__dict__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable Import Paths\n",
    "\n",
    "Renaming classes breaks pickle unless you use copyreg to maintain stable unpickling paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetterGameState:\n",
    "    def __init__(self, level=0, points=0, magic=5):\n",
    "        self.level = level\n",
    "        self.points = points\n",
    "        self.magic = magic\n",
    "\n",
    "# Register with same unpickle function\n",
    "copyreg.pickle(BetterGameState, pickle_game_state)\n",
    "\n",
    "state = BetterGameState()\n",
    "serialized = pickle.dumps(state)\n",
    "\n",
    "# Serialized data references unpickle function, not class name\n",
    "print(f\"Serialized data references unpickle_game_state function\")\n",
    "print(f\"Class can be renamed without breaking deserialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickle Security Warning\n",
    "\n",
    "**Never unpickle data from untrusted sources.** Pickle can execute arbitrary code during deserialization. Use JSON for untrusted communication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Safe for untrusted data\n",
    "data = {'level': 1, 'points': 1000, 'magic': 5}\n",
    "serialized = json.dumps(data)\n",
    "restored = json.loads(serialized)\n",
    "print(f\"JSON is safe for untrusted data: {restored}\")\n",
    "\n",
    "# Only use pickle between programs you control\n",
    "print(\"\\nUse pickle only for trusted internal communication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 69: Use decimal When Precision Is Paramount\n",
    "\n",
    "IEEE 754 floating point numbers introduce rounding errors in financial and precision-critical calculations. The `Decimal` class provides fixed-point arithmetic with configurable precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem with float\n",
    "\n",
    "Floating point arithmetic produces subtle errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate phone call cost\n",
    "rate = 1.45  # $/minute\n",
    "seconds = 3*60 + 42  # 3 minutes 42 seconds\n",
    "cost = rate * seconds / 60\n",
    "\n",
    "print(f\"Calculated cost: {cost}\")\n",
    "print(f\"Expected cost: 5.365\")\n",
    "print(f\"Error: {5.365 - cost}\")\n",
    "\n",
    "# Rounding makes it worse\n",
    "rounded = round(cost, 2)\n",
    "print(f\"\\nRounded cost: {rounded}\")\n",
    "print(f\"Expected: 5.37 (rounded up)\")\n",
    "print(f\"Actual: {rounded} (rounded down due to float error)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution: Decimal for Exact Arithmetic\n",
    "\n",
    "The `Decimal` class provides exact decimal arithmetic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "\n",
    "rate = Decimal('1.45')\n",
    "seconds = Decimal(3*60 + 42)\n",
    "cost = rate * seconds / Decimal(60)\n",
    "\n",
    "print(f\"Exact cost: {cost}\")\n",
    "print(f\"No rounding error!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decimal Construction: str vs float\n",
    "\n",
    "Always use string constructor to avoid float precision loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"String constructor (exact):\")\n",
    "print(Decimal('1.45'))\n",
    "\n",
    "print(\"\\nFloat constructor (imprecise):\")\n",
    "print(Decimal(1.45))\n",
    "\n",
    "print(\"\\nInteger constructor (exact):\")\n",
    "print(Decimal(456))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controlled Rounding with quantize\n",
    "\n",
    "The `quantize` method provides precise control over rounding behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import ROUND_UP\n",
    "\n",
    "# Round up to nearest cent\n",
    "cost = Decimal('5.365')\n",
    "rounded = cost.quantize(Decimal('0.01'), rounding=ROUND_UP)\n",
    "print(f\"Rounded {cost} to {rounded}\")\n",
    "\n",
    "# Handle small costs correctly\n",
    "rate = Decimal('0.05')\n",
    "seconds = Decimal('5')\n",
    "small_cost = rate * seconds / Decimal(60)\n",
    "print(f\"\\nSmall cost: {small_cost}\")\n",
    "\n",
    "# round() would give 0.00\n",
    "print(f\"Using round(): {round(float(small_cost), 2)}\")\n",
    "\n",
    "# quantize() preserves minimum charge\n",
    "rounded = small_cost.quantize(Decimal('0.01'), rounding=ROUND_UP)\n",
    "print(f\"Using quantize(): {rounded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Decimal\n",
    "\n",
    "**Financial calculations**: Monetary amounts require exact decimal arithmetic\n",
    "\n",
    "**Precision-critical domains**: Scientific measurements, accounting, legal requirements\n",
    "\n",
    "**Rounding control**: When you need specific rounding behaviors\n",
    "\n",
    "**Display precision**: When output must match specific decimal places\n",
    "\n",
    "For rational numbers with unlimited precision, consider the `Fraction` class from the `fractions` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item 70: Profile Before Optimizing\n",
    "\n",
    "Python's dynamic nature makes performance intuition unreliable. Always measure before optimizing to identify actual bottlenecks rather than perceived ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Profiling Mindset\n",
    "\n",
    "**Intuition is unreliable**: Dynamic features make performance counterintuitive\n",
    "\n",
    "**Measure first**: Profile to identify real bottlenecks\n",
    "\n",
    "**Focus optimization**: Target the biggest performance drains\n",
    "\n",
    "**Follow Amdahl's Law**: Optimizing fast code wastes effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Insertion Sort\n",
    "\n",
    "Consider an intentionally inefficient insertion sort implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertion_sort(data):\n",
    "    result = []\n",
    "    for value in data:\n",
    "        insert_value(result, value)\n",
    "    return result\n",
    "\n",
    "def insert_value(array, value):\n",
    "    for i, existing in enumerate(array):\n",
    "        if existing > value:\n",
    "            array.insert(i, value)\n",
    "            return\n",
    "    array.append(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "data = [randint(0, 100) for _ in range(100)]\n",
    "sorted_data = insertion_sort(data)\n",
    "print(f\"Sorted {len(data)} elements\")\n",
    "print(f\"First 10: {sorted_data[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python's Built-in Profiler\n",
    "\n",
    "The `cProfile` module identifies performance bottlenecks. For notebook usage, we can use the `%%prun` magic command or manually profile functions.\n",
    "\n",
    "In a production environment, you would run:\n",
    "\n",
    "```python\n",
    "import cProfile\n",
    "profiler = cProfile.Profile()\n",
    "profiler.runcall(insertion_sort, data)\n",
    "```\n",
    "\n",
    "The profiler output shows:\n",
    "- Function call counts\n",
    "- Total time spent in each function\n",
    "- Cumulative time including subfunctions\n",
    "- Time per call\n",
    "\n",
    "This reveals where optimization efforts should focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Profiling Principles\n",
    "\n",
    "**Profile before optimizing**: Measure to find real bottlenecks, not assumed ones\n",
    "\n",
    "**Use appropriate tools**: `cProfile` for function-level profiling, `line_profiler` for line-by-line analysis\n",
    "\n",
    "**Focus on hotspots**: Optimize the slowest 20% of code that causes 80% of runtime\n",
    "\n",
    "**Measure again**: Verify optimizations actually improve performance\n",
    "\n",
    "**Maintain readability**: Don't sacrifice code clarity for marginal gains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: Robustness and Performance\n",
    "\n",
    "This chapter covered essential patterns for building reliable, maintainable Python applications:\n",
    "\n",
    "**Exception handling**: Use try/except/else/finally blocks appropriately for different error scenarios\n",
    "\n",
    "**Context managers**: Abstract try/finally patterns with `contextlib` for cleaner, reusable code\n",
    "\n",
    "**Time zones**: Always use `datetime` with `pytz` for reliable time zone conversions\n",
    "\n",
    "**Serialization**: Make pickle reliable with `copyreg` for backward-compatible object persistence\n",
    "\n",
    "**Precision arithmetic**: Use `Decimal` for financial calculations requiring exact decimal arithmetic\n",
    "\n",
    "**Performance optimization**: Profile before optimizing to focus efforts on actual bottlenecks\n",
    "\n",
    "These practices form the foundation for robust Python applications that handle errors gracefully, manage resources properly, and perform efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
